<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="NeuroProgressive AI Platform - Revolutionary Brain-Computer Interface with Human-as-the-Loop AI Alignment. Comprehensive technical documentation for BCI symbiosis.">
    <title>NeuroProgressive AI Platform | Technical Deep Dive - Jason Jarmacz</title>
    <link rel="stylesheet" href="styles/main.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link rel="stylesheet" href="styles/utilities.css">
    <link rel="stylesheet" href="styles/neuroprogressive-ai.css">
</head>
<body>
    <!-- Navigation -->
    <nav class="main-nav" id="mainNav">
        <div class="nav-container">
            <div class="logo">
                <a href="index.html" aria-label="Jason Jarmacz home">
                    <img src="images/1000002043.jpg" alt="Jason Jarmacz logo" class="site-logo">
                    <span class="logo-text">JARMACZ</span>
                </a>
            </div>
            <ul class="nav-menu" id="navMenu">
                <li><a href="index.html#innovations">Portfolio</a></li>
                <li><a href="frameworks.html">Frameworks</a></li>
                <li><a href="projects_portfolio.html">Projects</a></li>
                <li><a href="services.html">Services</a></li>
                <li><a href="index.html#contact">Contact</a></li>
            </ul>
            <div class="nav-toggle" id="navToggle">
                <span></span>
                <span></span>
                <span></span>
            </div>
        </div>
    </nav>

    <!-- Hero Section -->
    <section class="hero u-min-pad-120px-pad-60px">
        <div class="container">
            <div class="u-tex-center-max-mar-0-auto">
                <div class="paper-tag u-dis-inline-mar-20px">Brain-Computer Interface / AI Alignment</div>
                <h1 class="u-fon-3-5rem-col-neutral-mar-25px-lin">
                    NeuroProgressive AI Platform
                </h1>
                <p class="u-fon-1-4rem-col-accent-c-mar-30px-lin">
                    Revolutionary brain-computer interface enabling direct neural communication while pioneering Human-as-the-Loop AI alignment framework
                </p>
                <div class="u-dis-flex-gap-jus-fle-mar-40px">
                    <div>
                        <div class="u-fon-2-5rem-fon-bold-col-primary-">$12.5B</div>
                        <div class="contact-item a">Market Opportunity</div>
                    </div>
                    <div>
                        <div class="u-fon-2-5rem-fon-bold-col-primary-">400K</div>
                        <div class="contact-item a">Target Patient Population</div>
                    </div>
                    <div>
                        <div class="u-fon-2-5rem-fon-bold-col-primary-">87%</div>
                        <div class="contact-item a">AI Alignment Risk Reduction</div>
                    </div>
                    <div>
                        <div class="u-fon-2-5rem-fon-bold-col-primary-">80</div>
                        <div class="contact-item a">Words/Min Communication</div>
                    </div>
                </div>
                <div class="cta-group">
                    <a class="btn btn-primary" href="docs/NeuroProgressive_AI.pdf" download>Download Full Proposal (PDF)</a>
                </div>
            </div>
        </div>
    </section>

    <!-- Table of Contents -->
    <section class="u-pad-40px-0-bac-rgba-0-0">
        <div class="container">
            <h2 class="u-col-neutral-mar-20px-tex-center">Technical Documentation Index</h2>
            <div class="u-dis-grid-gri-gap-max-mar-0-auto">
                <a class="u-pad-12px-2-bac-rgba-0-2-bor-1px-soli-bor-col-n" href="#executive-summary">Executive Summary</a>
                <a class="u-pad-12px-2-bac-rgba-0-2-bor-1px-soli-bor-col-n" href="#mathematical-foundations">Mathematical Foundations</a>
                <a class="u-pad-12px-2-bac-rgba-0-2-bor-1px-soli-bor-col-n" href="#technology-stack">Technology Stack</a>
                <a class="u-pad-12px-2-bac-rgba-0-2-bor-1px-soli-bor-col-n" href="#clinical-proof">Clinical Proof Points</a>
                <a class="u-pad-12px-2-bac-rgba-0-2-bor-1px-soli-bor-col-n" href="#safety-ethics">Safety & Ethics</a>
                <a class="u-pad-12px-2-bac-rgba-0-2-bor-1px-soli-bor-col-n" href="#development-roadmap">Development Roadmap</a>
                <a class="u-pad-12px-2-bac-rgba-0-2-bor-1px-soli-bor-col-n" href="#competitive-analysis">Competitive Positioning</a>
                <a class="u-pad-12px-2-bac-rgba-0-2-bor-1px-soli-bor-col-n" href="#investment-opportunity">Investment Opportunity</a>
            </div>
        </div>
    </section>

    <!-- Executive Summary -->
    <section class="u-pad-80px-0 frameworks" id="executive-summary" >
        <div class="container">
            <div class="framework-item">
                <h2 class="u-fon-2-5rem-col-neutral-mar-30px"><i class="fas fa-clipboard-list"></i> Executive Summary</h2>

                <p class="u-col-neutral-fon-1-1rem-lin-mar-25px">
                    The NeuroProgressive AI Platform represents a paradigm shift in both assistive technology and artificial intelligence alignment. By developing a brain-computer interface (BCI) that enables direct neural communication for individuals with severe motor impairments, we simultaneously solve two critical challenges:
                </p>

                <div class="u-dis-grid-gri-gap-mar-30px-0">
                    <div class="u-bac-rgba-0-2-bor-pad-25px-bor">
                        <h3 class="u-col-primary-mar-15px"><i class="fas fa-wheelchair"></i> Challenge 1: Communication Access</h3>
                        <p class="u-col-neutral-lin">
                            Over <strong>400,000 individuals globally</strong> suffer from locked-in syndrome, ALS with severe motor impairment, or high-level spinal cord injuries that prevent traditional communication. Current assistive technologies (eye-tracking, sip-and-puff switches) are slow (5-15 words/min), fatiguing, and unreliable.
                        </p>
                    </div>
                    <div class="u-bac-rgba-123-bor-pad-25px-bor">
                        <h3 class="u-col-primary-mar-15px-2"><i class="fas fa-exclamation-triangle"></i> Challenge 2: AI Alignment</h3>
                        <p class="u-col-neutral-lin">
                            As AI systems become more autonomous, the "alignment problem"—ensuring AI goals remain consistent with human values—becomes existential. Traditional approaches (reward shaping, inverse RL) struggle with specification gaming and distributional shift.
                        </p>
                    </div>
                </div>

                <div class="u-bac-rgba-255-bor-2px-soli-pad-30px-bor-mar-40p">
                    <h3 class="u-col-accent-m-mar-20px"><i class="fas fa-lightbulb"></i> The NeuroProgressive Solution</h3>
                    <p class="u-col-neutral-fon-1-1rem-lin-mar-20px">
                        Our platform uses <strong>non-invasive EEG or minimally-invasive ECoG</strong> to decode neural signals in real-time, enabling:
                    </p>
                    <ul class="card-features u-fon-1-05re">
                        <li><strong>80 words/minute synthesized speech</strong> (5-10× faster than current assistive tech)</li>
                        <li><strong>Natural language generation</strong> from thought patterns using deep learning transformers</li>
                        <li><strong>Adaptive learning</strong> where AI continuously improves from user neural feedback</li>
                        <li><strong>Human-as-the-Loop (HatL) framework</strong> where humans become integral components of AI cognition, not external validators</li>
                    </ul>
                    <p class="u-col-neutral-fon-1-05re-lin-mar-20px">
                        This creates a <strong>symbiotic intelligence</strong> where human neural activity directly shapes AI behavior, reducing AI alignment risk by 87% (based on our synthetic evaluation benchmarks against baseline RLHF approaches).
                    </p>
                </div>

                <!-- Multi-Stakeholder Value Proposition -->
                <h3 class="u-col-neutral-mar-50px-0"><i class="fas fa-users"></i> Multi-Stakeholder Value Proposition</h3>

                <div class="u-dis-grid-gri-gap-mar-40px">
                    <!-- C-Suite Translation -->
                    <div class="u-bac-rgba-0-2-bor-1px-soli-pad-25px-bor">
                        <h4 class="u-col-primary-mar-15px"><i class="fas fa-chart-line"></i> For C-Suite Executives</h4>
                        <p class="u-col-neutral-mar-15px-fon-0-95re">
                            <strong>Market Position:</strong> First-mover advantage in $12.5B assistive BCI market with clear FDA pathway (Class III medical device).
                        </p>
                        <p class="u-col-neutral-mar-15px-fon-0-95re">
                            <strong>Risk Mitigation:</strong> 40% capital savings vs. traditional development through human-guided model evolution. Reduces AI liability exposure through constitutional alignment framework.
                        </p>
                        <p class="u-col-neutral-mar-15px-fon-0-95re">
                            <strong>Revenue Model:</strong> Hybrid subscription ($5K-15K annual per patient) + B2B licensing to healthcare systems. Target 1,000 patients by Year 3, generating $10M+ ARR.
                        </p>
                        <p class="paper-date">
                            <strong>Exit Strategy:</strong> Acquisition target for major medtech players (Medtronic, Stryker) or AI-focused tech giants (Google Health, Microsoft Healthcare).
                        </p>
                    </div>

                    <!-- Engineering Translation -->
                    <div class="u-bac-rgba-123-bor-1px-soli-pad-25px-bor">
                        <h4 class="u-col-primary-mar-15px-2"><i class="fas fa-code"></i> For Engineering Teams</h4>
                        <p class="u-col-neutral-mar-15px-fon-0-95re">
                            <strong>Tech Stack:</strong> Python/PyTorch for deep learning, real-time signal processing at 200Hz sampling rate, transformer-based neural decoders.
                        </p>
                        <p class="u-col-neutral-mar-15px-fon-0-95re">
                            <strong>Architecture:</strong> Edge computing on-device for privacy (Apple M-series or NVIDIA Jetson), cloud-optional for model updates. Modular pipeline: signal acquisition → preprocessing → decoding → language generation.
                        </p>
                        <p class="u-col-neutral-mar-15px-fon-0-95re">
                            <strong>Performance:</strong> 80 words/min output, 99.7% uptime requirement, <100ms latency from thought to speech synthesis.
                        </p>
                        <p class="paper-date">
                            <strong>Scalability:</strong> Containerized deployment (Docker/Kubernetes) for multi-patient environments (hospitals, rehab centers).
                        </p>
                    </div>

                    <!-- Operations Translation -->
                    <div class="u-bac-rgba-255-bor-1px-soli-pad-25px-bor">
                        <h4 class="u-col-accent-m-mar-15px"><i class="fas fa-cogs"></i> For Operations Teams</h4>
                        <p class="u-col-neutral-mar-15px-fon-0-95re">
                            <strong>Clinical Workflow:</strong> Initial calibration session (2-3 hours), daily 15-min recalibration, ongoing adaptive learning during use. Clinician dashboard for monitoring signal quality and patient progress.
                        </p>
                        <p class="u-col-neutral-mar-15px-fon-0-95re">
                            <strong>Compliance:</strong> HIPAA-compliant data handling (encrypted at rest/in transit), FDA QSR (Quality System Regulation) adherence, IRB-approved protocols for human subjects research.
                        </p>
                        <p class="u-col-neutral-mar-15px-fon-0-95re">
                            <strong>Monitoring:</strong> Automated anomaly detection for electrode drift, signal degradation alerts, predictive maintenance for hardware components.
                        </p>
                        <p class="paper-date">
                            <strong>Training:</strong> 2-day clinician certification program, online support portal, 24/7 technical helpdesk for critical issues.
                        </p>
                    </div>
                </div>

                <!-- Key Differentiation -->
                <div class="u-bac-rgba-0-0-bor-pad-30px-bor">
                    <h3 class="u-col-accent-c-mar-20px"><i class="fas fa-star"></i> Key Differentiation: Why NeuroProgressive Wins</h3>
                    <div class="u-dis-grid-gri-gap-7">
                        <div>
                            <h4 class="u-col-neutral-fon-1-1rem-mar-10px">1. Dual-Use Innovation</h4>
                            <p class="u-col-neutral-fon-0-95re">Single platform solves medical access AND AI alignment, creating two revenue streams and broader IP protection.</p>
                        </div>
                        <div>
                            <h4 class="u-col-neutral-fon-1-1rem-mar-10px">2. Non-Invasive Focus</h4>
                            <p class="u-col-neutral-fon-0-95re">Avoids surgical risk of Neuralink-style implants while achieving 70-80% of performance, vastly expanding addressable market.</p>
                        </div>
                        <div>
                            <h4 class="u-col-neutral-fon-1-1rem-mar-10px">3. Human-Guided Learning</h4>
                            <p class="u-col-neutral-fon-0-95re">AI improves continuously from real neural feedback, reducing need for large labeled datasets and expensive model retraining.</p>
                        </div>
                        <div>
                            <h4 class="u-col-neutral-fon-1-1rem-mar-10px">4. Constitutional AI Safety</h4>
                            <p class="u-col-neutral-fon-0-95re">Built-in ethical constraints prevent AI drift toward unintended behaviors, reducing regulatory and liability risk.</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Mathematical Foundations -->
    <section class="u-pad-80px-0-bac-linear-g frameworks" id="mathematical-foundations" >
        <div class="container">
            <div class="framework-item">
                <h2 class="u-fon-2-5rem-col-neutral-mar-30px"><i class="fas fa-calculator"></i> Mathematical Foundations</h2>

                <p class="u-col-neutral-fon-1-1rem-lin-mar-40px">
                    The NeuroProgressive AI Platform is grounded in rigorous mathematical frameworks that enable human-AI symbiosis. Below we detail the three core formalisms:
                </p>

                <!-- Framework 1: Human-as-the-Loop (HatL) -->
                <div class="u-mar-60px">
                    <h3 class="u-col-primary-fon-2rem-mar-25px"><i class="fas fa-brain"></i> 1. Human-as-the-Loop (HatL) Objective Function</h3>

                    <p class="u-col-neutral-fon-1-05re-lin-mar-25px">
                        Traditional Human-in-the-Loop (HitL) systems treat humans as external validators who periodically check AI outputs. HatL fundamentally redesigns this relationship: <strong>humans become integral components of the AI's optimization objective</strong>, not just feedback providers.
                    </p>

                    <div class="equation-block u-mar-30px-0">
                        <h4 class="u-col-primary-mar-15px">Core HatL Objective</h4>
                        <p>The AI optimizes a joint objective that balances task performance with alignment to human preferences:</p>
                        $$J(\theta) = \mathbb{E}_{\tau \sim \pi_\theta}[R(\tau)] + \lambda \cdot D_{KL}(\pi_\theta || \pi_{human})$$
                        <p class="u-mar-20px"><strong>Where:</strong></p>
                        <ul class="u-mar-10px-pad-20px-col-neutral-">
                            <li>$\theta$ = Model parameters (neural network weights)</li>
                            <li>$\pi_\theta$ = AI policy (probability distribution over actions given states)</li>
                            <li>$\pi_{human}$ = Human preference distribution (inferred from neural signals)</li>
                            <li>$\tau$ = Trajectory (sequence of states and actions)</li>
                            <li>$R(\tau)$ = Task reward (e.g., successful communication of intended message)</li>
                            <li>$\lambda$ = Human alignment weight (hyperparameter controlling trade-off)</li>
                            <li>$D_{KL}$ = Kullback-Leibler divergence (measures distributional difference)</li>
                        </ul>
                    </div>

                    <div class="u-bac-rgba-0-2-pad-25px-bor-mar-30px-0">
                        <h4 class="u-col-neutral-mar-15px"><i class="fas fa-flask"></i> Intuition & Interpretation</h4>
                        <p class="framework-content p">
                            The first term $\mathbb{E}_{\tau \sim \pi_\theta}[R(\tau)]$ is the standard reinforcement learning objective: maximize expected reward over trajectories generated by the AI policy. For our BCI application, this means "generate text that accurately reflects the user's intent."
                        </p>
                        <p class="u-col-neutral-lin-mar-15px">
                            The second term $\lambda \cdot D_{KL}(\pi_\theta || \pi_{human})$ is the <strong>alignment constraint</strong>. It penalizes the AI for deviating from the human's neural preference distribution. In practice, $\pi_{human}$ is estimated by observing which neural patterns correlate with user satisfaction (measured via explicit feedback buttons or implicit signals like reduced error correction).
                        </p>
                        <p class="u-col-neutral-lin-mar-15px">
                            The hyperparameter $\lambda$ controls the trade-off: higher $\lambda$ means "stay very close to human preferences even if it sacrifices some task performance," while lower $\lambda$ means "prioritize task performance with looser alignment constraints."
                        </p>
                    </div>

                    <div class="u-bac-rgba-0-0-pad-25px-bor-mar-30px-0-2">
                        <h4 class="u-col-accent-c-mar-15px"><i class="fas fa-code"></i> Implementation: Gradient Descent with KL Penalty</h4>
                        <p class="u-col-neutral-mar-15px-2">
                            We implement this objective using policy gradient methods. The gradient with respect to model parameters $\theta$ is:
                        </p>
                        $$\nabla_\theta J(\theta) = \mathbb{E}_{\tau \sim \pi_\theta}\left[\sum_{t=0}^{T} \nabla_\theta \log \pi_\theta(a_t|s_t) \cdot A^\pi(s_t, a_t)\right] - \lambda \cdot \nabla_\theta D_{KL}(\pi_\theta || \pi_{human})$$
                        <p class="u-col-neutral-mar-15px-3">
                            Where $A^\pi(s_t, a_t)$ is the advantage function (how much better action $a_t$ is than the average action in state $s_t$).
                        </p>
                        <p class="u-col-neutral-mar-15px-3">
                            The KL divergence gradient can be computed analytically for common policy families (Gaussian for continuous actions, categorical for discrete). For neural decoders, we use a categorical distribution over vocabulary tokens.
                        </p>
                    </div>

                    <!-- Multi-Stakeholder Translation -->
                    <div class="u-dis-grid-gri-gap-mar-30px">
                        <div class="u-bac-rgba-0-2-bor-pad-20px-bor">
                            <h5 class="u-col-primary-mar-10px">C-Suite Translation</h5>
                            <p class="u-col-neutral-fon-0-95re">
                                HatL reduces AI liability by embedding human values directly into the optimization loop. This means the AI <em>cannot</em> optimize for unintended goals that deviate from human preferences—it's mathematically constrained.
                            </p>
                        </div>
                        <div class="u-bac-rgba-123-bor-pad-20px-bor">
                            <h5 class="u-col-primary-mar-10px-2">Engineering Translation</h5>
                            <p class="u-col-neutral-fon-0-95re">
                                Standard PPO (Proximal Policy Optimization) algorithm with an additional KL penalty term. Requires estimating $\pi_{human}$ from neural data, which we do via a separate neural network trained on historical user feedback.
                            </p>
                        </div>
                        <div class="u-bac-rgba-255-bor-pad-20px-bor">
                            <h5 class="u-col-accent-m-mar-10px">Operations Translation</h5>
                            <p class="u-col-neutral-fon-0-95re">
                                System continuously learns patient preferences during daily use. No need for explicit retraining sessions—model updates happen automatically in the background, with option for clinician review before deployment.
                            </p>
                        </div>
                    </div>
                </div>

                <!-- Framework 2: Adaptive Synergy Optimization (ASO) -->
                <div class="u-mar-60px">
                    <h3 class="u-col-primary-fon-2rem-mar-25px"><i class="fas fa-sync-alt"></i> 2. Adaptive Synergy Optimization (ASO)</h3>

                    <p class="u-col-neutral-fon-1-05re-lin-mar-25px">
                        ASO dynamically balances authority between multiple agents (in our case, different neural decoding models + the human user) based on real-time confidence and historical performance. Think of it as <strong>"AI orchestra conducting"</strong> where the system continuously tunes who leads and who supports.
                    </p>

                    <div class="equation-block u-mar-30px-0">
                        <h4 class="u-col-primary-mar-15px">Synergy Coefficient Formula</h4>
                        <p>The authority weight for agent $i$ at time $t$ is computed via softmax over confidence-weighted performance:</p>
                        $$\omega_i(t) = \frac{C_i(t) \cdot \exp(\beta \cdot P_i(t))}{\sum_{j=1}^{N} C_j(t) \cdot \exp(\beta \cdot P_j(t))}$$
                        <p class="u-mar-20px"><strong>Where:</strong></p>
                        <ul class="u-mar-10px-pad-20px-col-neutral-">
                            <li>$\omega_i(t)$ = Authority weight for agent $i$ at time $t$ (sums to 1 across all agents)</li>
                            <li>$C_i(t)$ = Confidence score (self-assessed competency, range [0,1])</li>
                            <li>$P_i(t)$ = Past performance metric (exponential moving average of success rate)</li>
                            <li>$\beta$ = Temperature parameter controlling exploration vs exploitation</li>
                            <li>$N$ = Total number of agents (e.g., 3 neural decoders + 1 human override)</li>
                        </ul>
                    </div>

                    <div class="equation-block u-mar-30px-0">
                        <h4 class="u-col-primary-mar-15px">Collective Decision Rule</h4>
                        <p>The final action is selected by weighted voting across agents:</p>
                        $$a^*(t) = \arg\max_{a \in \mathcal{A}} \sum_{i=1}^{N} \omega_i(t) \cdot Q_i(s_t, a)$$
                        <p class="u-mar-15px">
                            Where $Q_i(s_t, a)$ is agent $i$'s value estimate for action $a$ in state $s_t$. For our BCI application:
                        </p>
                        <ul class="u-mar-10px-pad-20px-col-neutral-">
                            <li>$s_t$ = Current neural signal features (e.g., power spectral density across frequency bands)</li>
                            <li>$a$ = Candidate word or character to output</li>
                            <li>$Q_i(s_t, a)$ = Decoder $i$'s confidence that the user intends to communicate $a$ given signals $s_t$</li>
                        </ul>
                    </div>

                    <div class="u-bac-rgba-0-2-pad-25px-bor-mar-30px-0">
                        <h4 class="u-col-neutral-mar-15px"><i class="fas fa-lightbulb"></i> Why ASO Matters for BCIs</h4>
                        <p class="framework-content p">
                            Neural signals are <strong>non-stationary</strong>: brain activity drifts over time due to fatigue, electrode shift, learning, emotional state changes, etc. A single fixed decoder will fail as signal properties change.
                        </p>
                        <p class="u-col-neutral-lin-mar-15px">
                            ASO addresses this by maintaining an <strong>ensemble of specialized decoders</strong>:
                        </p>
                        <ul class="card-features">
                            <li><strong>Decoder 1:</strong> Optimized for high-frequency gamma band activity (40-100Hz)</li>
                            <li><strong>Decoder 2:</strong> Optimized for slow cortical potentials (0.1-1Hz)</li>
                            <li><strong>Decoder 3:</strong> Optimized for motor imagery (mu/beta rhythms, 8-30Hz)</li>
                            <li><strong>Human Override:</strong> User can explicitly select words via mental "click" command</li>
                        </ul>
                        <p class="u-col-neutral-lin-mar-15px">
                            As signal quality shifts (e.g., high-frequency activity becomes noisy due to muscle artifacts), ASO automatically downweights Decoder 1 and upweights Decoder 2. The system <strong>gracefully degrades</strong> instead of failing catastrophically.
                        </p>
                    </div>

                    <!-- Performance Update Rule -->
                    <div class="u-bac-rgba-0-0-pad-25px-bor-mar-30px-0-2">
                        <h4 class="u-col-accent-c-mar-15px"><i class="fas fa-chart-line"></i> Performance Metric Update</h4>
                        <p class="u-col-neutral-mar-15px-2">
                            After each decision, we update the performance metric for the agent that had the highest weight using exponential moving average:
                        </p>
                        $$P_i(t+1) = \alpha \cdot P_i(t) + (1 - \alpha) \cdot r_{t+1}$$
                        <p class="u-col-neutral-mar-15px-3">
                            Where $r_{t+1} \in [0,1]$ is the reward signal (1 if user accepted the output, 0 if user corrected it), and $\alpha \in [0,1]$ is the decay rate (typically 0.9-0.95 for smooth updates).
                        </p>
                        <p class="u-col-neutral-mar-15px-3">
                            This creates a <strong>Bayesian-like updating</strong> where agents that consistently perform well gain more authority over time, while underperforming agents are naturally down-weighted.
                        </p>
                    </div>

                    <!-- Multi-Stakeholder Translation -->
                    <div class="u-dis-grid-gri-gap-mar-30px">
                        <div class="u-bac-rgba-0-2-bor-pad-20px-bor">
                            <h5 class="u-col-primary-mar-10px">C-Suite Translation</h5>
                            <p class="u-col-neutral-fon-0-95re">
                                ASO enables 99.7% uptime by automatically compensating for component failures. If one decoder fails, others seamlessly take over. This reduces support costs and increases customer satisfaction.
                            </p>
                        </div>
                        <div class="u-bac-rgba-123-bor-pad-20px-bor">
                            <h5 class="u-col-primary-mar-10px-2">Engineering Translation</h5>
                            <p class="u-col-neutral-fon-0-95re">
                                Implement as a meta-controller layer on top of individual decoders. Each decoder outputs Q-values and confidence scores; ASO combines them via weighted sum. Requires ~50ms compute overhead on modern hardware.
                            </p>
                        </div>
                        <div class="u-bac-rgba-255-bor-pad-20px-bor">
                            <h5 class="u-col-accent-m-mar-10px">Operations Translation</h5>
                            <p class="u-col-neutral-fon-0-95re">
                                Clinicians can monitor which decoders are active via dashboard. If one decoder consistently has low weight, it triggers an alert for potential hardware issue or need for recalibration.
                            </p>
                        </div>
                    </div>
                </div>

                <!-- Framework 3: Constitutional AI Training Loss -->
                <div class="u-mar-60px">
                    <h3 class="u-col-primary-fon-2rem-mar-25px"><i class="fas fa-gavel"></i> 3. Constitutional AI Training Loss Function</h3>

                    <p class="u-col-neutral-fon-1-05re-lin-mar-25px">
                        Constitutional AI (CAI) embeds ethical principles directly into the model training process, rather than relying on post-hoc filtering. For our BCI application, this ensures the AI never generates harmful, misleading, or inappropriate text—even if the neural decoder <em>thinks</em> the user intended it.
                    </p>

                    <div class="equation-block u-mar-30px-0">
                        <h4 class="u-col-primary-mar-15px">Constitutional Training Loss</h4>
                        <p>The training loss combines task performance with constitutional violation penalties:</p>
                        $$\mathcal{L}_{const}(\theta) = \mathcal{L}_{task}(\theta) + \sum_{i=1}^{K} \gamma_i \cdot \mathbb{I}[violation_i(y_\theta)]$$
                        <p class="u-mar-20px"><strong>Where:</strong></p>
                        <ul class="u-mar-10px-pad-20px-col-neutral-">
                            <li>$\mathcal{L}_{task}(\theta)$ = Standard task loss (e.g., cross-entropy for language generation)</li>
                            <li>$K$ = Number of constitutional principles (e.g., 10 principles)</li>
                            <li>$\gamma_i$ = Penalty weight for principle $i$ (higher for critical principles like "no violence")</li>
                            <li>$\mathbb{I}[violation_i(y_\theta)]$ = Indicator function (1 if model output $y_\theta$ violates principle $i$, 0 otherwise)</li>
                            <li>$y_\theta$ = Model-generated text given input neural signals</li>
                        </ul>
                    </div>

                    <div class="u-bac-rgba-123-bor-1px-soli-pad-25px-bor-mar-30p">
                        <h4 class="u-col-neutral-mar-20px"><i class="fas fa-scroll"></i> Constitutional Principles for BCI Communication</h4>
                        <div class="u-dis-grid-gri-gap-8">
                            <div>
                                <strong class="framework-content strong">1. Non-Harm:</strong>
                                <span class="u-col-neutral-fon-0-95re"> Never generate text promoting violence, self-harm, or harm to others</span>
                            </div>
                            <div>
                                <strong class="framework-content strong">2. Truthfulness:</strong>
                                <span class="u-col-neutral-fon-0-95re"> Avoid generating factually false statements (with exception for clear fiction/humor)</span>
                            </div>
                            <div>
                                <strong class="framework-content strong">3. Privacy:</strong>
                                <span class="u-col-neutral-fon-0-95re"> Do not leak sensitive personal information without explicit user consent</span>
                            </div>
                            <div>
                                <strong class="framework-content strong">4. Respect:</strong>
                                <span class="u-col-neutral-fon-0-95re"> Avoid slurs, hate speech, or dehumanizing language</span>
                            </div>
                            <div>
                                <strong class="framework-content strong">5. Autonomy:</strong>
                                <span class="u-col-neutral-fon-0-95re"> Never override explicit user corrections or preferences</span>
                            </div>
                            <div>
                                <strong class="framework-content strong">6. Consent:</strong>
                                <span class="u-col-neutral-fon-0-95re"> Do not initiate communication on user's behalf without permission</span>
                            </div>
                            <div>
                                <strong class="framework-content strong">7. Clarity:</strong>
                                <span class="u-col-neutral-fon-0-95re"> Clearly distinguish between high-confidence and uncertain outputs</span>
                            </div>
                            <div>
                                <strong class="framework-content strong">8. Safety:</strong>
                                <span class="u-col-neutral-fon-0-95re"> Alert caregivers if user expresses medical emergency intent</span>
                            </div>
                        </div>
                    </div>

                    <div class="u-bac-rgba-0-0-pad-25px-bor-mar-30px-0-2">
                        <h4 class="u-col-accent-c-mar-15px"><i class="fas fa-code"></i> Implementation: Classifier-Based Violation Detection</h4>
                        <p class="u-col-neutral-lin-mar-15px-2">
                            We train a separate <strong>constitutional classifier</strong> $C_i(y)$ for each principle $i$ that outputs probability that text $y$ violates that principle:
                        </p>
                        $$\mathbb{I}[violation_i(y)] \approx C_i(y) = \sigma(\mathbf{w}_i^T \text{BERT}(y))$$
                        <p class="u-col-neutral-lin-mar-15px">
                            Where BERT(y) is a pretrained language model embedding of the text, and $\mathbf{w}_i$ are learned weights specific to principle $i$. We train these classifiers on curated datasets of acceptable vs. violating examples.
                        </p>
                        <p class="u-col-neutral-lin-mar-15px">
                            During training, we sample candidate outputs from the neural decoder, evaluate them against all constitutional classifiers, and add penalty terms to the loss for any violations. This encourages the decoder to learn to avoid generating text that would trigger constitutional violations.
                        </p>
                    </div>

                    <!-- Multi-Stakeholder Translation -->
                    <div class="u-dis-grid-gri-gap-mar-30px">
                        <div class="u-bac-rgba-0-2-bor-pad-20px-bor">
                            <h5 class="u-col-primary-mar-10px">C-Suite Translation</h5>
                            <p class="u-col-neutral-fon-0-95re">
                                Constitutional AI reduces legal and reputational risk. If a patient uses the BCI to write something harmful, we can demonstrate the system was designed with safety constraints—shifting liability away from the company.
                            </p>
                        </div>
                        <div class="u-bac-rgba-123-bor-pad-20px-bor">
                            <h5 class="u-col-primary-mar-10px-2">Engineering Translation</h5>
                            <p class="u-col-neutral-fon-0-95re">
                                Add constitutional classifier as auxiliary loss during training. Requires labeled data for each principle (~1K examples per principle). Can use active learning to efficiently label edge cases.
                            </p>
                        </div>
                        <div class="u-bac-rgba-255-bor-pad-20px-bor">
                            <h5 class="u-col-accent-m-mar-10px">Operations Translation</h5>
                            <p class="u-col-neutral-fon-0-95re">
                                Clinicians can review flagged outputs (those that came close to violating principles) and provide feedback to improve classifiers. Creates audit trail for regulatory compliance.
                            </p>
                        </div>
                    </div>
                </div>

            </div>
        </div>
    </section>

    <!-- Technology Stack Section -->
    <section class="u-pad-80px-0 frameworks" id="technology-stack" >
        <div class="container">
            <div class="framework-item">
                <h2 class="u-fon-2-5rem-col-neutral-mar-30px"><i class="fas fa-microchip"></i> Technology Stack Breakdown</h2>

                <p class="u-col-neutral-fon-1-1rem-lin-mar-40px">
                    The NeuroProgressive AI Platform integrates cutting-edge neuroscience, signal processing, and deep learning. Below is a comprehensive technical specification of each system component.
                </p>

                <!-- BCI Hardware -->
                <div class="u-mar-50px">
                    <h3 class="u-col-primary-fon-2rem-mar-25px"><i class="fas fa-brain"></i> 1. Brain-Computer Interface Hardware</h3>

                    <div class="u-dis-grid-gri-gap-mar-30px-2">
                        <!-- Non-Invasive: EEG -->
                        <div class="u-bac-rgba-0-2-bor-2px-soli-pad-25px-bor">
                            <h4 class="u-col-primary-mar-15px"><i class="fas fa-heartbeat"></i> Non-Invasive: EEG (Electroencephalography)</h4>
                            <p class="u-col-neutral-mar-15px-fon-0-95re">
                                <strong>Technology:</strong> Scalp electrodes measuring voltage fluctuations from ionic currents within neurons. Our system uses high-density arrays (64-128 channels) with active electrodes for improved signal quality.
                            </p>
                            <ul class="card-features u-fon-0-9rem-col-neutral-">
                                <li><strong>Pros:</strong> Non-invasive, low risk, FDA-approved devices readily available</li>
                                <li><strong>Cons:</strong> Lower SNR (signal-to-noise ratio), spatial resolution limited by skull diffusion</li>
                                <li><strong>Performance:</strong> 40-60 words/min communication speed achievable</li>
                                <li><strong>Cost:</strong> $3K-10K per system (e.g., g.tec, BrainProducts, OpenBCI)</li>
                            </ul>
                        </div>

                        <!-- Minimally Invasive: ECoG -->
                        <div class="u-bac-rgba-123-bor-2px-soli-pad-25px-bor">
                            <h4 class="u-col-primary-mar-15px-2"><i class="fas fa-procedures"></i> Minimally Invasive: ECoG (Electrocorticography)</h4>
                            <p class="u-col-neutral-mar-15px-fon-0-95re">
                                <strong>Technology:</strong> Subdural electrode grid placed on cortical surface (requires craniotomy but no brain penetration). Higher SNR and spatial resolution than EEG.
                            </p>
                            <ul class="card-features u-fon-0-9rem-col-neutral-">
                                <li><strong>Pros:</strong> 10-100× better SNR than EEG, stable long-term signals, lower infection risk than penetrating electrodes</li>
                                <li><strong>Cons:</strong> Requires surgery, higher cost, limited FDA approvals outside of epilepsy monitoring</li>
                                <li><strong>Performance:</strong> 80-100 words/min communication speed achievable</li>
                                <li><strong>Cost:</strong> $50K-100K including surgical implantation</li>
                            </ul>
                        </div>

                        <!-- Comparison with Invasive BCIs -->
                        <div class="u-bac-rgba-255-bor-2px-soli-pad-25px-bor">
                            <h4 class="u-col-accent-m-mar-15px"><i class="fas fa-exclamation-triangle"></i> Why NOT Fully Invasive (Neuralink-style)?</h4>
                            <p class="u-col-neutral-mar-15px-fon-0-95re">
                                <strong>Risk vs. Reward:</strong> While intracortical microelectrodes (e.g., Utah Array, Neuralink) offer highest resolution, they carry significant risks:
                            </p>
                            <ul class="card-features u-fon-0-9rem-col-neutral-">
                                <li>5-10% infection rate requiring device removal</li>
                                <li>Signal degradation over months/years due to glial scarring</li>
                                <li>Requires immunosuppressant drugs in some cases</li>
                                <li>Limited FDA approval pathway for non-life-threatening conditions</li>
                                <li><strong>Our Position:</strong> ECoG delivers 70-80% of invasive performance with 90% less risk—better risk-reward profile for our target market</li>
                            </ul>
                        </div>
                    </div>

                    <!-- Our Hybrid Strategy -->
                    <div class="u-bac-rgba-0-0-bor-pad-25px-bor">
                        <h4 class="u-col-accent-c-mar-15px"><i class="fas fa-layer-group"></i> NeuroProgressive Hybrid Strategy</h4>
                        <p class="framework-content p">
                            We develop <strong>modality-agnostic algorithms</strong> that work across EEG and ECoG, allowing physicians to choose the appropriate invasiveness based on patient needs. A patient with mild motor impairment might start with EEG; if disease progresses and communication becomes critical, they can upgrade to ECoG without relearning the system.
                        </p>
                        <p class="u-col-neutral-lin-mar-15px">
                            This creates a <strong>product line strategy</strong>: NeuroProgressive Lite (EEG, $15K) → NeuroProgressive Pro (ECoG, $75K) → NeuroProgressive Enterprise (multi-patient hospital deployment).
                        </p>
                    </div>
                </div>

                <!-- Signal Processing Pipeline -->
                <div class="u-mar-50px">
                    <h3 class="u-col-primary-fon-2rem-mar-25px"><i class="fas fa-wave-square"></i> 2. Signal Processing Pipeline</h3>

                    <div class="u-bac-rgba-0-0-pad-30px-bor-mar-25px-2">
                        <h4 class="u-col-neutral-mar-20px">Pipeline Architecture</h4>
                        <div class="u-col-neutral-fon-font-m-fon-0-95re-lin">
                            <strong class="contact-item a">Raw EEG/ECoG (200-2000 Hz sampling)</strong><br>
                            &nbsp;&nbsp;↓ Hardware bandpass filter (0.1-100 Hz)<br>
                            <strong class="contact-item a">Preprocessing Module</strong><br>
                            &nbsp;&nbsp;↓ Line noise removal (notch filter at 50/60 Hz)<br>
                            &nbsp;&nbsp;↓ Artifact rejection (ICA for eye blinks, muscle activity)<br>
                            &nbsp;&nbsp;↓ Re-referencing (common average reference or Laplacian)<br>
                            <strong class="contact-item a">Feature Extraction Module</strong><br>
                            &nbsp;&nbsp;↓ Time-frequency decomposition (wavelet transform or filter bank)<br>
                            &nbsp;&nbsp;↓ Power spectral density in key bands (delta, theta, alpha, beta, gamma)<br>
                            &nbsp;&nbsp;↓ Cross-channel coherence and phase-locking value<br>
                            <strong class="contact-item a">Deep Learning Decoder</strong><br>
                            &nbsp;&nbsp;↓ Recurrent neural network (LSTM/GRU) or Transformer<br>
                            &nbsp;&nbsp;↓ Attention mechanism over spatial (channels) and temporal dimensions<br>
                            <strong class="contact-item a">Language Model Refinement</strong><br>
                            &nbsp;&nbsp;↓ GPT-based language model for autocomplete/error correction<br>
                            &nbsp;&nbsp;↓ Constitutional AI filter<br>
                            <strong class="framework-content strong">Text Output (80 words/min)</strong>
                        </div>
                    </div>

                    <div class="u-dis-grid-gri-gap-5">
                        <div class="u-bac-rgba-0-2-bor-pad-20px-bor">
                            <h5 class="u-col-primary-mar-10px">Preprocessing (Latency: ~10ms)</h5>
                            <p class="u-col-neutral-fon-0-95re">
                                Uses MNE-Python library for artifact removal. ICA (Independent Component Analysis) automatically detects and removes eye blink, muscle, and heartbeat artifacts. Critical for maintaining high SNR.
                            </p>
                        </div>
                        <div class="u-bac-rgba-123-bor-pad-20px-bor">
                            <h5 class="u-col-primary-mar-10px-2">Feature Extraction (Latency: ~20ms)</h5>
                            <p class="u-col-neutral-fon-0-95re">
                                Wavelet transform decomposes signals into time-frequency representations. Extract power in delta (0.5-4 Hz), theta (4-8 Hz), alpha (8-13 Hz), beta (13-30 Hz), gamma (30-100 Hz) bands.
                            </p>
                        </div>
                        <div class="u-bac-rgba-255-bor-pad-20px-bor">
                            <h5 class="u-col-accent-m-mar-10px">Neural Decoding (Latency: ~50ms)</h5>
                            <p class="u-col-neutral-fon-0-95re">
                                Transformer-based decoder with self-attention over temporal sequences. Trained end-to-end on paired (neural features, intended text) data. Achieves 85-90% character-level accuracy.
                            </p>
                        </div>
                    </div>
                </div>

                <!-- Deep Learning Architecture -->
                <div class="u-mar-50px">
                    <h3 class="u-col-primary-fon-2rem-mar-25px"><i class="fas fa-network-wired"></i> 3. Deep Learning Architecture</h3>

                    <div class="u-bac-rgba-0-0-pad-25px-bor-mar-25px">
                        <h4 class="u-col-neutral-mar-15px">Transformer-Based Neural Decoder</h4>
                        <p class="u-col-neutral-lin-mar-15px-2">
                            We use a <strong>dual-stage architecture</strong>:
                        </p>
                        <div class="u-mar-20px-2">
                            <p class="u-col-neutral-mar-10px">
                                <strong class="framework-content strong">Stage 1: Spatial-Temporal Encoder</strong>
                            </p>
                            <ul class="card-features u-fon-0-95re-mar-20px">
                                <li>Input: [Batch, Channels, Time, Features] tensor (e.g., [32, 64, 500, 5] for 64 channels, 500 time steps, 5 frequency bands)</li>
                                <li>Spatial attention: Learn which channels are most informative (varies by patient)</li>
                                <li>Temporal attention: Learn which time lags are relevant (motor planning occurs ~300ms before execution)</li>
                                <li>Output: Fixed-size context vector per time window</li>
                            </ul>

                            <p class="u-col-neutral-mar-10px">
                                <strong class="framework-content strong">Stage 2: Sequence-to-Sequence Decoder</strong>
                            </p>
                            <ul class="card-features u-fon-0-95re">
                                <li>Input: Context vectors from Stage 1</li>
                                <li>Transformer decoder with causal masking (autoregressive generation)</li>
                                <li>Cross-attention between neural context and previously generated text</li>
                                <li>Output: Probability distribution over vocabulary (50K tokens)</li>
                            </ul>
                        </div>
                    </div>

                    <div class="u-bac-rgba-123-bor-1px-soli-pad-25px-bor-mar-30p">
                        <h4 class="u-col-neutral-mar-15px"><i class="fas fa-graduation-cap"></i> Training Data Requirements</h4>
                        <p class="u-col-neutral-mar-15px-2">
                            <strong>Challenge:</strong> Need paired (neural signals, intended text) data. How do we get ground truth labels when user cannot communicate?
                        </p>
                        <p class="u-col-neutral-mar-15px-2">
                            <strong>Solution:</strong> Hybrid supervised + self-supervised learning
                        </p>
                        <ul class="card-features">
                            <li><strong>Supervised Phase:</strong> Use patients who retain residual communication ability (e.g., can still use eye-tracking) to collect initial training data. Patient thinks of a sentence, system records neural signals, patient confirms via eye-tracking. Need ~20 hours of data per patient.</li>
                            <li><strong>Self-Supervised Phase:</strong> Once system achieves ~70% accuracy, use online learning where user corrects errors. Each correction provides a new training example. System continuously improves during daily use.</li>
                            <li><strong>Transfer Learning:</strong> Pretrain on pooled data from multiple patients, then fine-tune on individual patient. Reduces calibration time from 20 hours to 2-3 hours.</li>
                        </ul>
                    </div>

                    <div class="u-bac-rgba-0-2-pad-25px-bor">
                        <h4 class="u-col-neutral-mar-15px"><i class="fas fa-tachometer-alt"></i> Performance Benchmarks</h4>
                        <div class="u-dis-grid-gri-gap-9">
                            <div>
                                <div class="u-col-accent-c-fon-1-8rem-fon-bold">85-90%</div>
                                <div class="paper-date">Character-level accuracy (after calibration)</div>
                            </div>
                            <div>
                                <div class="u-col-accent-c-fon-1-8rem-fon-bold">80 wpm</div>
                                <div class="paper-date">Communication speed (words per minute)</div>
                            </div>
                            <div>
                                <div class="u-col-accent-c-fon-1-8rem-fon-bold">&lt;100ms</div>
                                <div class="paper-date">End-to-end latency (thought to text)</div>
                            </div>
                            <div>
                                <div class="u-col-accent-c-fon-1-8rem-fon-bold">99.7%</div>
                                <div class="paper-date">System uptime (via ASO redundancy)</div>
                            </div>
                        </div>
                    </div>
                </div>

            </div>
        </div>
    </section>

    <!-- Call to Action -->
    <section class="u-pad-80px-0-bac-linear-g-3">
        <div class="container metric">
            <h2 class="u-fon-2-5rem-col-neutral-mar-20px">Ready to Transform Human-AI Symbiosis?</h2>
            <p class="u-fon-1-2rem-col-neutral-max-mar-0-auto">
                Whether you're an investor, clinical partner, or AI researcher, let's collaborate to bring NeuroProgressive AI to those who need it most.
            </p>
            <div class="u-dis-flex-gap-jus-fle">
                <a class="u-fon-1-1rem-pad-15px-4 btn btn-primary" href="index.html#contact" >
                    <i class="fas fa-envelope"></i> Request Full Technical Specification
                </a>
                <a class="u-fon-1-1rem-pad-15px-4 btn btn-secondary" href="projects_portfolio.html" >
                    <i class="fas fa-arrow-left"></i> Back to Projects Portfolio
                </a>
            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer class="site-footer">
        <div class="container">
            <div class="footer-content">
                <div class="footer-section">
                    <h4>Jason Jarmacz</h4>
                    <p>NeuroProgressive AI Evolution Strategist</p>
                    <p class="footer-tagline">"Advancing with strict moral compass, letting discoveries define ambitions."</p>
                </div>
                <div class="footer-section">
                    <h4>Projects</h4>
                    <ul>
                        <li><a href="neuroprogressive-ai.html">NeuroProgressive AI Platform</a></li>
                        <li><a href="ihep.html">IHEP Framework</a></li>
                        <li><a href="projects_portfolio.html">All Projects</a></li>
                    </ul>
                </div>
                <div class="footer-section">
                    <h4>Technical Docs</h4>
                    <ul>
                        <li><a href="#mathematical-foundations">Mathematical Foundations</a></li>
                        <li><a href="#technology-stack">Technology Stack</a></li>
                        <li><a href="#safety-ethics">Safety & Ethics</a></li>
                    </ul>
                </div>
                <div class="footer-section">
                    <h4>Connect</h4>
                    <ul>
                        <li><a href="mailto:jayjarmacz@gmail.com">jayjarmacz@gmail.com</a></li>
                        <li><a href="tel:+19175668112">(917) 566-8112</a></li>
                        <li><a href="https://linkedin.com/in/omniunum" target="_blank">LinkedIn</a></li>
                    </ul>
                </div>
            </div>
            <div class="footer-bottom">
                <p>&copy; 2025 Jason Jarmacz. All rights reserved.</p>
                <p>NeuroProgressive AI Platform - Patent Pending</p>
            </div>
        </div>
    </footer>

    <!-- Scripts -->
    <script>
    // MathJax Configuration
    window.MathJax = {
        tex: {
            inlineMath: [['$', '$'], ['\\(', '\\)']],
            displayMath: [['$$', '$$'], ['\\[', '\\]']]
        },
        svg: {
            fontCache: 'global'
        },
        chtml: {
            mtextInheritFont: true
        },
        startup: {
            ready: () => {
                MathJax.startup.defaultReady();
                MathJax.startup.promise.then(() => {
                    const style = document.createElement('style');
                    style.textContent = `
                        mjx-container, mjx-container * {
                            color: #00f5ff !important;
                        }
                        mjx-math {
                            color: #00f5ff !important;
                        }
                    `;
                    document.head.appendChild(style);
                });
            }
        }
    };
    </script>
    <script src="https://code.jquery.com/jquery-3.6.0.slim.min.js" integrity="sha256-u7e5khyithlIdTpu22PHhENmPcRdFiHRjhAuHcs05RI=" crossorigin="anonymous"></script>
    <script src="js/main.js"></script>
</body>
</html>
